{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRo38Db1J3GbIaExHBJZhK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hectorcamachoz/SVM-y-Multiple-Testing/blob/main/A3_1_594557.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM y Multiple Testing\n",
        "\n",
        "En esta actividad se trabajara con la base de datos de la que se habló en mi clase de Inteligencia Artificial, que consiste de 83 muestras y 2308 variables de entrada, que consisten en la expresión génica estandarizada de distintos genes. La variable de salida cuenta con valores numéricos del 1 al 4 que\n",
        "corresponden a distintos tipos de cáncer.\n",
        "\n",
        "**1.** Lo primero que se realizara sera importar la base de datos, revisar que no tenga huecos. Tambien, se calculara la diferencia de promedios entre las clases 2 y 4, se imprimiran los 10 genes con mayor diferencia.\n"
      ],
      "metadata": {
        "id": "SNF_SGyqrBS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('A3.1_Khan.csv')\n",
        "print(\"Tabla con numero de huecos en variables: \")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df_2 = df[df['y'] == 2]\n",
        "df_4 = df[df['y'] == 4]\n",
        "\n",
        "gen_2 = df_2.drop(columns=['y'])\n",
        "gen_4 = df_4.drop(columns=['y'])\n",
        "\n",
        "promedios_2 = gen_2.mean()\n",
        "promedios_4 = gen_4.mean()\n",
        "\n",
        "dif = (promedios_2 - promedios_4).abs()\n",
        "\n",
        "top_10_genes = dif.sort_values(ascending=False).head(10)\n",
        "\n",
        "print(\"\\nTop 10 genes con mayor diferencia de promedios entre clases 2 y 4:\")\n",
        "print(top_10_genes)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-t7qWvmrBHh",
        "outputId": "f13c0914-2999-4656-8d74-2d61007c43c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla con numero de huecos en variables: \n",
            "X1       0\n",
            "X2       0\n",
            "X3       0\n",
            "X4       0\n",
            "X5       0\n",
            "        ..\n",
            "X2305    0\n",
            "X2306    0\n",
            "X2307    0\n",
            "X2308    0\n",
            "y        0\n",
            "Length: 2309, dtype: int64\n",
            "\n",
            "Top 10 genes con mayor diferencia de promedios entre clases 2 y 4:\n",
            "X187     3.323151\n",
            "X509     2.906537\n",
            "X2046    2.424515\n",
            "X2050    2.401783\n",
            "X129     2.165185\n",
            "X1645    2.065460\n",
            "X1319    2.045941\n",
            "X1955    2.037340\n",
            "X1003    2.011337\n",
            "X246     1.837830\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considero que la diferencia entre las clases puede indicar que podria haber una diferencia real entre la clase 2 y 4 y que no es un simple resultado de variacion al azar, y que podria haber una relacion entre la variable y la clase . En este caso el gen con mayor diferencia en ambas clases es la X187, y la decima variable con mayor diferencia fue X246"
      ],
      "metadata": {
        "id": "xTQKXJCDwH_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** A continuacion calculare el estadistico t y el p value para comparar las medias de los genes entre la clase 2 y 4, Utilizando la metodologia de Bonferroni, Holm y Benajmini-Hochberg (para utilizar estas metodologias utilice chatGPT)"
      ],
      "metadata": {
        "id": "_2SiNLnvyANp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "df_2_4 = df[df['y'].isin([2, 4])]\n",
        "df_filtered = df_2_4.drop(columns=['y'])\n",
        "t_stats = []\n",
        "p_values = []\n",
        "\n",
        "for gen in df_filtered.columns[1:]:  # Excluyendo columna 'clase'\n",
        "    t, p = ttest_ind(df_2[gen], df_4[gen], equal_var=False)\n",
        "    t_stats.append(t)\n",
        "    p_values.append(p)\n",
        "\n",
        "# Bonferroni\n",
        "_, p_bonf, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
        "\n",
        "# Holm\n",
        "_, p_holm, _, _ = multipletests(p_values, alpha=0.05, method='holm')\n",
        "\n",
        "# Benjamini-Hochberg (FDR)\n",
        "_, p_bh, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
        "\n",
        "resultados = pd.DataFrame({\n",
        "    'Gen': df_filtered.columns[1:],\n",
        "    't_stat': t_stats,\n",
        "    'p_value': p_values,\n",
        "    'p_bonf': p_bonf,\n",
        "    'p_holm': p_holm,\n",
        "    'p_bh': p_bh\n",
        "})\n",
        "significativos_bonf = resultados[resultados['p_bonf'] < 0.05]\n",
        "significativos_holm = resultados[resultados['p_holm'] < 0.05]\n",
        "significativos_bh = resultados[resultados['p_bh'] < 0.05]\n",
        "\n",
        "# Imprime los genes significativos\n",
        "print(\"Genes significativos con Bonferroni:\\n\", significativos_bonf)\n",
        "print(\"\\nGenes significativos con Holm:\\n\", significativos_holm)\n",
        "print(\"\\nGenes significativos con Benjamini-Hochberg:\\n\", significativos_bh)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3sCJEWtx_6j",
        "outputId": "3514c366-efd3-468d-d880-b4b9d08c0daf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genes significativos con Bonferroni:\n",
            "         Gen     t_stat       p_value        p_bonf        p_holm          p_bh\n",
            "0        X2  -6.900138  7.383962e-08  1.703480e-04  1.681328e-04  5.495097e-06\n",
            "34      X36   5.610781  7.885432e-07  1.819169e-03  1.785262e-03  4.134476e-05\n",
            "65      X67  -4.793322  1.413077e-05  3.259970e-02  3.166707e-02  4.865626e-04\n",
            "127    X129  -8.412602  2.516574e-09  5.805735e-06  5.757920e-06  2.902868e-07\n",
            "172    X174  -6.974367  5.603441e-09  1.292714e-05  1.281507e-05  6.155780e-07\n",
            "...     ...        ...           ...           ...           ...           ...\n",
            "2044  X2046 -10.842463  1.769295e-14  4.081764e-11  4.071148e-11  5.831091e-12\n",
            "2048  X2050 -10.983249  4.084836e-15  9.423716e-12  9.415546e-12  3.060886e-12\n",
            "2113  X2115  -5.069148  7.286580e-06  1.681014e-02  1.640209e-02  2.949148e-04\n",
            "2144  X2146  -7.567062  7.001831e-10  1.615322e-06  1.604119e-06  9.501897e-08\n",
            "2245  X2247  -6.050112  3.066047e-07  7.073370e-04  6.956860e-04  1.813685e-05\n",
            "\n",
            "[72 rows x 6 columns]\n",
            "\n",
            "Genes significativos con Holm:\n",
            "         Gen     t_stat       p_value        p_bonf        p_holm          p_bh\n",
            "0        X2  -6.900138  7.383962e-08  1.703480e-04  1.681328e-04  5.495097e-06\n",
            "34      X36   5.610781  7.885432e-07  1.819169e-03  1.785262e-03  4.134476e-05\n",
            "65      X67  -4.793322  1.413077e-05  3.259970e-02  3.166707e-02  4.865626e-04\n",
            "127    X129  -8.412602  2.516574e-09  5.805735e-06  5.757920e-06  2.902868e-07\n",
            "172    X174  -6.974367  5.603441e-09  1.292714e-05  1.281507e-05  6.155780e-07\n",
            "...     ...        ...           ...           ...           ...           ...\n",
            "2044  X2046 -10.842463  1.769295e-14  4.081764e-11  4.071148e-11  5.831091e-12\n",
            "2048  X2050 -10.983249  4.084836e-15  9.423716e-12  9.415546e-12  3.060886e-12\n",
            "2113  X2115  -5.069148  7.286580e-06  1.681014e-02  1.640209e-02  2.949148e-04\n",
            "2144  X2146  -7.567062  7.001831e-10  1.615322e-06  1.604119e-06  9.501897e-08\n",
            "2245  X2247  -6.050112  3.066047e-07  7.073370e-04  6.956860e-04  1.813685e-05\n",
            "\n",
            "[72 rows x 6 columns]\n",
            "\n",
            "Genes significativos con Benjamini-Hochberg:\n",
            "         Gen    t_stat       p_value    p_bonf    p_holm      p_bh\n",
            "0        X2 -6.900138  7.383962e-08  0.000170  0.000168  0.000005\n",
            "1        X3  4.255350  9.621623e-05  0.221971  0.213023  0.002342\n",
            "27      X29  3.452663  1.113505e-03  1.000000  1.000000  0.014115\n",
            "34      X36  5.610781  7.885432e-07  0.001819  0.001785  0.000041\n",
            "50      X52  3.802063  4.065804e-04  0.937981  0.879027  0.006425\n",
            "...     ...       ...           ...       ...       ...       ...\n",
            "2276  X2278 -3.724263  6.339875e-04  1.000000  1.000000  0.009141\n",
            "2293  X2295  3.849629  3.283459e-04  0.757494  0.711854  0.005411\n",
            "2298  X2300  4.011332  2.057612e-04  0.474691  0.450205  0.003956\n",
            "2299  X2301 -3.999225  2.017711e-04  0.465486  0.441677  0.003912\n",
            "2301  X2303  4.723085  2.491232e-05  0.057473  0.055654  0.000777\n",
            "\n",
            "[296 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En las tablas anteriores se indica cuales son los genes mas significativos osea menores a 0.05 de cada metododologia.\n",
        "\n",
        "\n",
        "**3.**A continuacion, se realizara una comparación de las medias de las 4 clases con el metodo de pruebas de analisis de varianza ANOVA, utilizando la funcion f_oneway de scipy.stats"
      ],
      "metadata": {
        "id": "4Kd4MJNOa3nP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qegsnSVpqWqG",
        "outputId": "2e0a4588-224a-4c91-e397-77c67ede0b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genes significativos con Bonferroni:\n",
            "         Gen     F_stat       p_value    p_bonf          p_bh\n",
            "0        X2  15.297268  5.834294e-09  0.000013  1.035812e-06\n",
            "83      X85   8.769972  1.773256e-05  0.040927  4.131361e-04\n",
            "84      X86  13.451983  5.310526e-08  0.000123  3.714150e-06\n",
            "106    X108  11.593171  5.148264e-07  0.001188  2.583086e-05\n",
            "122    X124  16.840008  9.535525e-10  0.000002  3.308794e-07\n",
            "...     ...        ...           ...       ...           ...\n",
            "2197  X2199  14.966904  8.634494e-09  0.000020  1.107134e-06\n",
            "2198  X2200  10.198054  2.920720e-06  0.006741  9.630032e-05\n",
            "2216  X2218   8.696276  1.947610e-05  0.044951  4.364160e-04\n",
            "2229  X2231   9.514228  6.904243e-06  0.015935  1.943292e-04\n",
            "2302  X2304  11.910425  3.482065e-07  0.000804  1.913478e-05\n",
            "\n",
            "[104 rows x 5 columns]\n",
            "\n",
            "Genes significativos con Benjamini-Hochberg:\n",
            "         Gen     F_stat       p_value    p_bonf      p_bh\n",
            "0        X2  15.297268  5.834294e-09  0.000013  0.000001\n",
            "8       X10   3.844195  1.055997e-02  1.000000  0.048648\n",
            "16      X18   7.873769  5.572845e-05  0.128621  0.001005\n",
            "28      X30   5.898389  7.179708e-04  1.000000  0.006382\n",
            "32      X34   5.645293  9.988159e-04  1.000000  0.008263\n",
            "...     ...        ...           ...       ...       ...\n",
            "2296  X2298   4.179982  6.800703e-03  1.000000  0.035236\n",
            "2298  X2300   5.253144  1.667340e-03  1.000000  0.012195\n",
            "2300  X2302   4.740217  3.263274e-03  1.000000  0.020084\n",
            "2302  X2304  11.910425  3.482065e-07  0.000804  0.000019\n",
            "2303  X2305   8.167278  3.825941e-05  0.088303  0.000755\n",
            "\n",
            "[505 rows x 5 columns]\n",
            "\n",
            "Genes significativos: \n",
            "         Gen     F_stat       p_value    p_bonf      p_bh\n",
            "0        X2  15.297268  5.834294e-09  0.000013  0.000001\n",
            "1        X3   3.477778  1.705916e-02  1.000000  0.068475\n",
            "2        X4   3.056248  2.957441e-02  1.000000  0.102643\n",
            "8       X10   3.844195  1.055997e-02  1.000000  0.048648\n",
            "16      X18   7.873769  5.572845e-05  0.128621  0.001005\n",
            "...     ...        ...           ...       ...       ...\n",
            "2296  X2298   4.179982  6.800703e-03  1.000000  0.035236\n",
            "2298  X2300   5.253144  1.667340e-03  1.000000  0.012195\n",
            "2300  X2302   4.740217  3.263274e-03  1.000000  0.020084\n",
            "2302  X2304  11.910425  3.482065e-07  0.000804  0.000019\n",
            "2303  X2305   8.167278  3.825941e-05  0.088303  0.000755\n",
            "\n",
            "[765 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "gen_1 = df[df['y'] == 1].drop(columns='y')\n",
        "gen_2 = df.drop(columns='y')\n",
        "gen_3 = df[df['y'] == 3].drop(columns='y')\n",
        "gen_4 = df.drop(columns='y')\n",
        "\n",
        "f_stat_an, p_value_an = f_oneway(gen_1, gen_2, gen_3, gen_4)\n",
        "\n",
        "_, p_bonf, _, _ = multipletests(p_value_an, alpha=0.05, method='bonferroni')\n",
        "_, p_bh, _, _ = multipletests(p_value_an, alpha=0.05, method='fdr_bh')\n",
        "\n",
        "genes = df.columns[1:]\n",
        "resultados_an = pd.DataFrame({\n",
        "    'Gen': genes,\n",
        "    'F_stat': f_stat_an,\n",
        "    'p_value': p_value_an,\n",
        "    'p_bonf': p_bonf,\n",
        "    'p_bh': p_bh\n",
        "})\n",
        "\n",
        "val_bonf = resultados_an[resultados_an['p_bonf'] < 0.05]\n",
        "val_bh = resultados_an[resultados_an['p_bh'] < 0.05]\n",
        "\n",
        "print(\"Genes significativos utilizando anova y Bonferroni:\\n\", val_bonf)\n",
        "print(\"\\nGenes significativos utilizando anova y Benjamini-Hochberg:\\n\", val_bh)\n",
        "\n",
        "print('\\nGenes significativos con resultados de anova: \\n', resultados_an[resultados_an['p_value'] < 0.05])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En estos resultados se puede observar una menor reduccion en la cantidad de variables seleccionadas, exceptuando para los generados exclusivamente con f_oneway."
      ],
      "metadata": {
        "id": "P1KhhSW6EQc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** Ahora se dividiran los datos en train y test, (50/50), se generaran tres modelos con SVM uno con kernel lineal, uno con kernel polinomial de tercer orden y otro con kernel radial. Seleccionare un determinado numero de variables basado en los mejores resultados anteriores, para asi evitar los tiempos extensos de procesamiento, como esta actividad es de objetivo formativo, se ignorara que se esta cayendo en una fuga de datos."
      ],
      "metadata": {
        "id": "bOFGp2NU5Ws9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "nm = resultados_an[resultados_an['p_value'] < 0.05]['Gen']\n",
        "\n",
        "x = df[nm]\n",
        "\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42)\n",
        "\n",
        "#Modelo kernel lineal\n",
        "model_lineal = SVC(C= 1, kernel='linear', probability=True)\n",
        "model_lineal.fit(X_train, y_train)\n",
        "y_pred_lineal = model_lineal.predict(X_test)\n",
        "\n",
        "#Modelo kernel polinomial 3er grado\n",
        "model_polinomial = SVC(C = 1, kernel='poly', degree=3, probability=True)\n",
        "model_polinomial.fit(X_train, y_train)\n",
        "y_pred_polinomial = model_polinomial.predict(X_test)\n",
        "\n",
        "#Modelo kernel radial\n",
        "model_radial = SVC(C = 1, kernel='rbf', probability=True)\n",
        "model_radial.fit(X_train, y_train)\n",
        "y_pred_radial = model_radial.predict(X_test)\n",
        "\n",
        "print(\"\\nResultados Modelo con Kernel Lineal:\")\n",
        "print(confusion_matrix(y_test, y_pred_lineal))\n",
        "print(classification_report(y_test, y_pred_lineal))\n",
        "\n",
        "print(\"\\nResultados Modelo con Kernel Polinomial:\")\n",
        "print(confusion_matrix(y_test, y_pred_polinomial))\n",
        "print(classification_report(y_test, y_pred_polinomial))\n",
        "\n",
        "print(\"\\nResultados Modelo con Kernel Radial:\")\n",
        "print(confusion_matrix(y_test, y_pred_radial))\n",
        "print(classification_report(y_test, y_pred_radial))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wNrzGz6vfnm",
        "outputId": "1c346aec-f78c-4d71-b731-525e23f10f5c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados Modelo con Kernel Lineal:\n",
            "[[ 8  0  0  0]\n",
            " [ 0 15  0  0]\n",
            " [ 0  0  5  3]\n",
            " [ 0  0  0 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       1.00      0.62      0.77         8\n",
            "           4       0.79      1.00      0.88        11\n",
            "\n",
            "    accuracy                           0.93        42\n",
            "   macro avg       0.95      0.91      0.91        42\n",
            "weighted avg       0.94      0.93      0.92        42\n",
            "\n",
            "\n",
            "Resultados Modelo con Kernel Polinomial:\n",
            "[[ 8  0  0  0]\n",
            " [ 0 13  1  1]\n",
            " [ 0  0  5  3]\n",
            " [ 0  1  1  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       0.93      0.87      0.90        15\n",
            "           3       0.71      0.62      0.67         8\n",
            "           4       0.69      0.82      0.75        11\n",
            "\n",
            "    accuracy                           0.83        42\n",
            "   macro avg       0.83      0.83      0.83        42\n",
            "weighted avg       0.84      0.83      0.83        42\n",
            "\n",
            "\n",
            "Resultados Modelo con Kernel Radial:\n",
            "[[ 7  1  0  0]\n",
            " [ 0 14  0  1]\n",
            " [ 0  1  5  2]\n",
            " [ 0  0  0 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.88      0.93         8\n",
            "           2       0.88      0.93      0.90        15\n",
            "           3       1.00      0.62      0.77         8\n",
            "           4       0.79      1.00      0.88        11\n",
            "\n",
            "    accuracy                           0.88        42\n",
            "   macro avg       0.92      0.86      0.87        42\n",
            "weighted avg       0.90      0.88      0.88        42\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizando los resultados obtenidos, se puede concluir que el mejor modelo fue el del kernel lineal, ya que obtuvo un f1_score alto en casi todas las clases, y tuvo un accuracy general de 0.93. Antes de llegar a este resultado realice multples particiones de datos para averiguar cual era el mejor valor, ya que al inicio, habia realizado una particion 70/20 y habia observado que me quedaban muy pocas observaciones para el test, por lo tanto, lo cambie a 50/50"
      ],
      "metadata": {
        "id": "jQyjWnqJDk4P"
      }
    }
  ]
}